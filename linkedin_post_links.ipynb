{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import sleep\n",
    "from datetime import datetime, timedelta\n",
    "import pyperclip\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "opt = webdriver.ChromeOptions()\n",
    "opt.add_argument(\"--start-maximized\")\n",
    "opt.add_experimental_option(\"excludeSwitches\", [\"disable-popup-blocking\"])\n",
    "# opt.add_argument('--headless')\n",
    "# opt.add_argument('--disable-gpu')\n",
    "# opt.add_argument(\"--lang=en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_internet_connection():\n",
    "    \"\"\"check for active internet\"\"\"\n",
    "    try:\n",
    "        print(\"checking for active internet .....\")\n",
    "        requests.get('http://www.google.com', timeout=50)\n",
    "        print(\"Internet connection is available.\")\n",
    "        return True\n",
    "    except requests.ConnectionError:\n",
    "        print(\"Internet connection is not available.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login(login_username, login_password, base_link, driver):\n",
    "    \"\"\"\n",
    "    login into linkedin \n",
    "    \"\"\"\n",
    "    driver.get(base_link)\n",
    "    print(\"logging in please wait ....\")\n",
    "    try:\n",
    "        username=WebDriverWait(driver, 30).until(\n",
    "                EC.presence_of_element_located((By.XPATH, './/input[@id=\"username\"]'))\n",
    "            )\n",
    "        username.send_keys(login_username)\n",
    "        password=WebDriverWait(driver, 30).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, './/input[@id=\"password\"]'))\n",
    "                )\n",
    "        password.send_keys(login_password)\n",
    "        password.send_keys(Keys.ENTER)\n",
    "        side_bar=WebDriverWait(driver, 30).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, './/div[@aria-label=\"Side Bar\"]')))\n",
    "        print(\"logging successfull\")\n",
    "        return True\n",
    "    except TimeoutException:\n",
    "        print(\"opps! login failed ...\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_id(url):\n",
    "    \"\"\"\n",
    "    This function extracts the post ID from a LinkedIn URL.\n",
    "    \"\"\"\n",
    "    post_id = []\n",
    "    # Iterate over each string in the list\n",
    "    for s in url.split(\"posts/\")[-1].split(\"-\"):\n",
    "        # Find all numbers in the current string\n",
    "        numbers = re.findall(r'\\b\\d{19}\\b', s)\n",
    "        # Convert the extracted numbers to integers and add to the list\n",
    "        post_id.extend(map(int, numbers))\n",
    "    return post_id[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unix_timestamp(post_id):\n",
    "    \"\"\"\n",
    "    This function converts a post ID to a Unix timestamp.\n",
    "    \"\"\"\n",
    "    # Convert the post ID to a binary string.\n",
    "    as_binary = format(int(post_id), \"b\")\n",
    "    # Take the first 41 characters of the binary string.\n",
    "    first_41_chars = as_binary[:41]\n",
    "    # Convert the binary string to a Unix timestamp.\n",
    "    timestamp = int(first_41_chars, 2) / 1000\n",
    "    return timestamp\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unix_timestamp_to_string(timestamp):\n",
    "    \"\"\"\n",
    "    This function converts a Unix timestamp to a string.\n",
    "    \"\"\"\n",
    "    # Create a datetime object from the Unix timestamp.\n",
    "    date_object = datetime.utcfromtimestamp(timestamp)\n",
    "    # Format the datetime object in a string format.\n",
    "    formatted_date = date_object.strftime(\"%Y-%m-%d %H:%M\")\n",
    "    return formatted_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_difference_calculater(given_date_str):\n",
    "    \"\"\" this will check if the post date is older than 4 years or not  \"\"\"\n",
    "    given_date = datetime.strptime(given_date_str, '%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Current date\n",
    "    current_date = datetime.now()\n",
    "\n",
    "    # Date 4 years ago from today\n",
    "    date_4_years_ago = current_date - timedelta(days=4*365)\n",
    "\n",
    "    # Check if the given date is older than 4 years\n",
    "    is_older_than_4_years = given_date < date_4_years_ago\n",
    "    return is_older_than_4_years\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(url):\n",
    "    \"\"\"\n",
    "    This function takes a LinkedIn URL and returns the date of the post.\n",
    "    \"\"\"\n",
    "    # Extract the post ID from the URL.\n",
    "    post_id = get_post_id(url)\n",
    "    # Convert the post ID to a Unix timestamp.\n",
    "    unix_timestamp = extract_unix_timestamp(post_id)\n",
    "    # Convert the Unix timestamp to a human-readable date.\n",
    "    human_date_format = unix_timestamp_to_string(unix_timestamp)\n",
    "    return human_date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_post_to_center_of_screen(driver, post_element):\n",
    "    \"\"\" scroll the post to the center of screen to make it clickable \"\"\"\n",
    "    viewport_height = driver.execute_script(\"return window.innerHeight;\")\n",
    "    element_y = post_element.location['y']\n",
    "    element_height = post_element.size['height']\n",
    "    # Calculate scroll position to center the element\n",
    "    scroll_y = element_y - (viewport_height / 2) + (element_height / 2)\n",
    "    # Scroll the page using JavaScript to center the element\n",
    "    driver.execute_script(f\"window.scrollTo(0, {scroll_y});\")\n",
    "    # Optional: Add a delay to see the scroll action (adjust as needed)\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_each_post_details(driver, each_post):\n",
    "    \"\"\" get post link and date of a post \"\"\"\n",
    "    # click to open post menu \n",
    "    try:\n",
    "        post_header=each_post.find_element(by=By.XPATH, value=f'.//div[@class=\"relative\"]')\n",
    "        scroll_post_to_center_of_screen(driver,post_header)\n",
    "        post_header.find_element(by=By.XPATH, value=f'.//div[@class=\"artdeco-dropdown artdeco-dropdown--placement-bottom artdeco-dropdown--justification-right ember-view\"]').click()\n",
    "        post_menu=WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, './/div[@class=\"artdeco-dropdown__content-inner\"]'))\n",
    "            )\n",
    "        # copied to clipboard\n",
    "        post_menu.find_elements(by=By.XPATH, value=f'.//li')[1].click()\n",
    "        post_url=pyperclip.paste()\n",
    "        linked_in_time=each_post.find_element(by=By.XPATH, value=f'.//a[@class=\"app-aware-link  update-components-actor__sub-description-link\"]').text.split(\" \")[0]\n",
    "        date_time_stamp=get_date(post_url)\n",
    "        return {\"post_url\":post_url,\n",
    "                \"linkedin_time\":linked_in_time,\n",
    "                \"time_stamp\":date_time_stamp\n",
    "                }\n",
    "    except TimeoutException:\n",
    "        print(\"error in loading post menu\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"error in loading post \\n{e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_profile_posts(driver, profile_link):\n",
    "    \"\"\"load posts page of a profile\"\"\"\n",
    "    print(f\"loading posts for \\n{profile_link} \")\n",
    "    driver.get(f\"{profile_link}/recent-activity/all/\")   \n",
    "    try:\n",
    "        WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, './/div[@class=\"pv-recent-activity-detail__core-rail\"]')))\n",
    "        print(\"posts page loaded successfully\")\n",
    "        return True\n",
    "    except TimeoutException:\n",
    "        print(\"error in loading post page\")\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_n_get_posts(driver, len_prevs_results):\n",
    "    \"\"\"scroll and wait for the results to load or end\"\"\"\n",
    "    continue_scrapping_flag=True\n",
    "    secs_to_wait=60  #secs to wait to load more results on scrolling\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    sleep(2)\n",
    "#     see if end results message is show\n",
    "\n",
    "    try:\n",
    "        WebDriverWait(driver, secs_to_wait).until(\n",
    "            EC.invisibility_of_element_located((By.XPATH, './/div[@class=\"artdeco-loader artdeco-loader--small ember-view\"]'))\n",
    "            )\n",
    "    except:\n",
    "        continue_scrapping_flag=False\n",
    "        print(\"Timed out waiting for the loading more results.\\n\\nEnding Scrolling\")\n",
    "        return continue_scrapping_flag\n",
    "        \n",
    "\n",
    "    for x in range(secs_to_wait):\n",
    "        sleep(1)\n",
    "        all_new_results=len(driver.find_elements(by=By.XPATH, value='.//li[@class=\"profile-creator-shared-feed-update__container\"]'))\n",
    "        if all_new_results>len_prevs_results:\n",
    "            return continue_scrapping_flag \n",
    "    \n",
    "    continue_scrapping_flag=False\n",
    "    print(\"Ending Scrolling\")\n",
    "    return continue_scrapping_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(result_dicts, data_folder_path, output_file_name):\n",
    "    \"\"\"writes result dicts to output folder\"\"\"\n",
    "    df = pd.DataFrame(result_dicts)\n",
    "    df.to_csv(f'{data_folder_path}/{output_file_name.replace(\" \",\"_\").replace(\",\",\"_\")}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_pofile_posts(driver,profile_link,all_profile_posts_dicts):\n",
    "    \"\"\"scrape all the posts for a profile and their relevent details\"\"\"\n",
    "    load_profile_posts(driver, profile_link)\n",
    "    print(\"scolling n getting posts url\")\n",
    "    profile_result_dicts=[]\n",
    "    while True:\n",
    "        continue_scolling_flag=scroll_n_get_posts(driver, len(profile_result_dicts))\n",
    "\n",
    "        all_posts=driver.find_elements(by=By.XPATH, value='.//li[@class=\"profile-creator-shared-feed-update__container\"]')\n",
    "        for each_post in all_posts[len(profile_result_dicts):]:\n",
    "            # skip first scrapped results\n",
    "            if len(profile_result_dicts)==len(all_posts):\n",
    "                break\n",
    "            \n",
    "            each_result_dict=get_each_post_details(driver,each_post)\n",
    "            if each_result_dict != False:\n",
    "\n",
    "                each_result_dict[\"profile_link\"]=profile_link\n",
    "                if date_difference_calculater(each_result_dict[\"time_stamp\"]):\n",
    "                    continue_scolling_flag=False\n",
    "                    print(\"post older than 4 years, stopping scrapping\")\n",
    "                    \n",
    "                    break\n",
    "                else:\n",
    "                    profile_result_dicts.append(each_result_dict)\n",
    "                    all_profile_posts_dicts.append(each_result_dict)\n",
    "                    save_results(all_profile_posts_dicts, data_folder_path, output_file_name)\n",
    "        if not continue_scolling_flag:\n",
    "            break\n",
    "    return all_profile_posts_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_link=\"https://www.linkedin.com/login?fromSignIn=true&trk=guest_homepage-basic_nav-header-signin\"\n",
    "login_username=\"linkedinnlinkd@gmail.com\"\n",
    "login_password=\"temp123++--\"\n",
    "data_folder_path = f\"data/extra/linkedin\"\n",
    "output_file_name=\"metadata_links.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not os.path.exists(data_folder_path)):\n",
    "    os.makedirs(data_folder_path)\n",
    "    print(f'new data folder {data_folder_path} created success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_links_list=[\"https://www.linkedin.com/in/hassan-qaiser-3686b0169/\",\n",
    "    \"https://www.linkedin.com/in/qualman/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking for active internet .....\n",
      "Internet connection is available.\n",
      "logging in please wait ....\n",
      "logging successfull\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if check_internet_connection():\n",
    "    driver = webdriver.Chrome(options=opt)\n",
    "    login(login_username, login_password, base_link, driver)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading posts for \n",
      "https://www.linkedin.com/in/hassan-qaiser-3686b0169/ \n",
      "posts page loaded successfully\n",
      "scolling n getting posts url\n",
      "error in loading post \n",
      "\n",
      "    Pyperclip could not find a copy/paste mechanism for your system.\n",
      "    For more information, please visit https://pyperclip.readthedocs.io/en/latest/index.html#not-implemented-error \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-1421b4824a89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_profile_posts_dicts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprofile_link\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprofile_links_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mall_profile_posts_dicts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscrape_pofile_posts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprofile_link\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_profile_posts_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-c0480e2814d6>\u001b[0m in \u001b[0;36mscrape_pofile_posts\u001b[0;34m(driver, profile_link, all_profile_posts_dicts)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0meach_result_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"profile_link\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile_link\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mdate_difference_calculater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meach_result_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time_stamp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mcontinue_scolling_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post older than 4 years, stopping scrapping\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "all_profile_posts_dicts=[]\n",
    "for profile_link in profile_links_list:\n",
    "    all_profile_posts_dicts=scrape_pofile_posts(driver,profile_link,all_profile_posts_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congrats! scrapping completed\n"
     ]
    }
   ],
   "source": [
    "driver.close()\n",
    "print(\"congrats! scrapping completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
